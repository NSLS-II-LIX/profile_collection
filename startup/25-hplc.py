import uuid
import time,os
from enum import Enum
from ophyd import (EpicsSignal, EpicsSignalRO, Device, Component as Cpt)
from collections import ChainMap
from ophyd import DeviceStatus
from bluesky.preprocessors import (monitor_during_decorator, run_decorator,
                                   stage_decorator, subs_decorator)
from bluesky.plan_stubs import (complete, kickoff, collect, monitor, unmonitor,
                                trigger_and_read)
from bluesky.callbacks import LivePlot

default_hplc_export_file = 'File\tZ:\\hplc_export.txt'

class HPLCStatus(str, Enum):
    idle = "idle"
    waiting_injected = "waiting_injected"
    waiting_done = "waiting_done"

class HPLC(Device):
    ready = Cpt(EpicsSignal, 'io1')
    injected = Cpt(EpicsSignalRO, 'io2')
    done = Cpt(EpicsSignalRO, 'io3')
    bypass = Cpt(EpicsSignal, '_bypass')
    
    def __init__(self, *args, read_filepath, write_filepath, **kwargs):
        self.hplc_status = HPLCStatus.idle
        self._injected_status = None
        self._done_status = None
        self._bypass_status = None
        self._resource = None
        self._read_filepath = read_filepath
        self._write_filepath = write_filepath
        super().__init__(*args, **kwargs)

    def stage(self):
        self.injected.subscribe(self._injected_changed)
        self.done.subscribe(self._done_changed)
        self.bypass.subscribe(self._bypass_changed)

    def unstage(self):
        self.injected.clear_sub(self._injected_changed)
        self.done.clear_sub(self._done_changed)
        self.bypass.clear_sub(self._bypass_changed)
        self._injected_status = None
        self._done_status = None
        self._bypass_status = None
        # self._resource = None

    def kickoff(self):
        """
        Set 'ready' to True and return a status object tied to 'injected'.
        """
        self.ready.set(1)
        self.hplc_status = HPLCStatus.waiting_injected
        self._injected_status = DeviceStatus(self.injected)
        self._done_status = DeviceStatus(self.done)
        return self._injected_status

    def complete(self):
        """
        Return a status object tied to 'done'.
        """
        if self._done_status is None:
            raise RuntimeError("must call kickoff() before complete()")
        return self._done_status

    def collect(self):
        """
        Yield events that reference the data files generated by HPLC.
        the HPLC run using a batch file should always export data into /GPFS/xf16id/Windows/hplc_export.txt
        """

        # in principle there are lots of things that can be saved
        # for now just keep the chromatograms
        sections = readShimadzuDatafile('/GPFS/xf16id/Windows/hplc_export.txt', return_all_sections=True)
        
        import numpy as np
        yield {'time': time.time(),
               'seq_num': 1,
               'data': {'foo': np.random.rand(2048, 1)},
               'timestamps': {'foo': time.time()}}

        # TODO Decide whether you want to 'chunk' the dataset into 'events'.
        # Insert a datum per event and yield a partial event document.
        #for i in range(1):
        #    yield {'time': time.time(),
        #           'seq_num': i+1,
        #           'data': {'foo': np.random.rand(2048, 1)},  #datum_id},
        #           'timestamps': {'foo': time.time()}}

    def describe_collect(self):
        return {self.name: {'foo': {'dtype': 'array',
                             'shape': (2048,),
                             'source': 'TO DO'}}}

    def _injected_changed(self, value, old_value, **kwargs):
        """Mark the status object returned by 'kickoff' as finished when
        injected goes from 0 to 1."""
        if self._injected_status is None:
            return
        if (old_value == 0) and (value == 1):
            self.ready.set(0)
            self.hplc_status = HPLCStatus.waiting_done
            self._injected_status._finished()

    def _done_changed(self, value, old_value, **kwargs):
        """Mark the status object returned by 'complete' as finished when
        done goes from 0 to 1."""
        if self._done_status is None:
            return
        if (old_value == 0) and (value == 1):
            self.hplc_status = HPLCStatus.idle
            self._done_status._finished()

    def _bypass_changed(self, value, old_value, **kwargs):
        """Mark the status object returned by 'complete' as finished when
        done goes from 0 to 1."""
        if value == 0:
            return
        print('Bypass used: {}, hplc state: {}'.format(value, self.hplc_status))
        if (value == 1) and self.hplc_status == HPLCStatus.waiting_injected:
            self._injected_changed(1,0)
        elif (value == 2) and self.hplc_status == HPLCStatus.waiting_done:
            self._done_changed(1,0)
        self.bypass.set(0)

hplc = HPLC('XF:16IDC-ES:Sol{ctrl}HPLC', name='hplc', read_filepath=None, write_filepath=None)

class LoudLivePlot(LivePlot):
    def event(self, doc):
        if 'usb4000_region1_luminscence' in doc['data']:
            print(doc['seq_num'])
        super().event(doc)


def hplc_scan(detectors, monitors, *, md=None):
    if md is None:
        md = {}
    md = ChainMap(md,
                  {'plan_name': 'hplc_scan'})

    @fast_shutter_decorator() 
    #@subs_decorator(LiveTable([usb4000.region1.luminescence.name]))
    #@subs_decorator(LoudLivePlot(usb4000.region1.luminescence.name))
    @stage_decorator([hplc] + detectors)
    #@monitor_during_decorator(monitors)
    @run_decorator(md=md)
    def inner():
        print('Beamline Ready... waiting for HPLC Injected Signal')
        yield from kickoff(hplc, wait=True)
        print('Acquiring data...')
        for mo in monitors:
            yield from monitor(mo)
        status = yield from complete(hplc, wait=False)
        while True:
            yield from trigger_and_read(detectors)  # one 'primary' event per loop
            if status.done:
                break
        for mo in monitors:
            yield from unmonitor(mo)
        print('Collecting the data...')
        yield from collect(hplc)

    return (yield from inner())

def collect_hplc(sample_name, exp):#, CV=24, flowrate=0.5)
    change_sample(sample_name)
    sol.select_flow_cell('middle')
    #time = CV/flowrate
    #no_of_cts = time * 60/exp
    set_pil_num_images(1)
    pilatus_ct_time(exp)
    updata_metadata()
    RE(hplc_scan(detectors=[pil1M, pilW1, pilW2, em1, em2], monitors=[]))

    
def readShimadzuSection(section):
    """ the chromtographic data section starts with a header
        followed by 2-column data
        the input is a collection of strings
    """
    xdata = []
    ydata = []
    for line in section:
        tt = line.split()
        if len(tt)==2:
            try:
                x=float(tt[0])
            except ValueError:
                continue
            try:
                y=float(tt[1])
            except ValueError:
                continue
            xdata.append(x)
            ydata.append(y)
    return xdata,ydata

def writeShimadzuDatafile(fn, sections):
    """ warning: there is no error checking
        sections is a dictionary, each item correspond to a section, the key is the section name
    """
    fd = open(fn, "w+")
    for k,s in sections.items():
        fd.write(k + '\r\n' + '\r\n'.join(s) + '\r\n' + '\r\n')
    fd.close()
    
def readShimadzuDatafile(fn, return_all_sections=False):
    """ read the ascii data from Shimadzu Lab Solutions software
        the file appear to be split in to multiple sections, each starts with [section name], 
        and ends with a empty line
        returns the data in the sections titled 
            [LC Chromatogram(Detector A-Ch1)] and [LC Chromatogram(Detector B-Ch1)]
    """
    fd = open(fn, "r")
    lines = fd.read().split('\n')
    fd.close()
    
    sects = []
    while True:
        try:
            idx = lines.index('')
        except ValueError:
            break
        if idx>0:
            sects.append(lines[:idx])
        lines = lines[idx+1:]
    
    sections = {}
    for i in range(len(sects)):
        sections[sects[i][0]] = sects[i][1:]
    
    if return_all_sections:
        return sections
    
    data = {}
    header_str = '\n'.join(sections["[Header]"]) + '\n'.join(sections["[Original Files]"])
    for k in sections.keys():
        if "[LC Chromatogram" in k:
            x,y = readShimadzuSection(sections[k])
            data[k] = [x,y]
    
    return header_str,data

def createShimadzuBatchFile(spreadsheet_fn, sheet_name='Samples', check_sname=True):
    template_batch_file = "/GPFS/xf16id/Windows/HPLC/template/JB_test_GUI_Q.txt"
    sections = readShimadzuDatafile(template_batch_file, return_all_sections=True)
    dd = parseSpreadsheet(spreadsheet_fn, sheet_name=sheet_name)
    nrows = len(dd[list(dd.keys())[0]])

    try:
        run_id   # this should exist after login()
    except NameError:
        run_id = None
    if run_id is None:    
        run_id = 'test'   # use this if not logged in

    default_data_path = '/GPFS/xf16id/Windows/HPLC/%s/%s/' % (proposal_id,run_id)
    default_win_HPLC_dir = 'Z:\\HPLC\\'
    default_win_data_path = default_win_HPLC_dir+run_id+'\\'
    # make directory, makedirs() is defined in 02-utils.py
    makedirs(default_data_path)

    # some contents of the sample info need to be generated automatically
    dd['Sample ID'] = {}
    dd['Data File'] = {}
    for i in range(nrows):
        dd['Sample ID'][i] = dd['Sample Name'][i]
        dd['Data File'][i] = default_win_data_path+dd['Sample Name'][i]+'.lcd'
        dd['Method File'][i] = default_win_HPLC_dir+dd['Method File'][i]
    
    # make sure there are no repeating sample names
    samples = list(dd['Sample Name'].values())
    if check_sname:
        for sampleName in samples:
            if samples.count(sampleName)>1:
                raise Exception('duplicate sample name: %s' % sampleName)
            if not check_sample_name(sampleName):
                raise Exception("change sample name: %s, files already exist." % sampleName)
    
    sections['[ASCII Convert]'][1] = default_hplc_export_file
    sections['[ASCII Convert]'][2] = 'Auto-Increment\t0'
    # create the batch table
    batch_table = []
    batch_table.append('# of Row\t%d' % nrows)
    batch_table.append(sections['[Batch Table]'][1])
    batch_para_name = sections['[Batch Table]'][1].split('\t')
    batch_para_value = sections['[Batch Table]'][2].split('\t')

    for i in range(nrows):
        entry = []
        for j in range(len(batch_para_name)):
            if batch_para_name[j] in dd.keys():
                entry.append(str(dd[batch_para_name[j]][i]))
            else:
                entry.append(str(batch_para_value[j]))
        batch_table.append('\t'.join(entry))

    sections['[Batch Table]'] = batch_table
    
    batch_file_name = sheet_name+'_batch.txt'
    writeShimadzuDatafile(default_data_path+batch_file_name, sections)
    
    return batch_file_name,default_win_data_path,samples

    
def run_hplc_from_spreadsheet(spreadsheet_fn, sheet_name='Samples', exp=1, save_retry=5):
    batch_fn,winDataPath,samples = createShimadzuBatchFile(spreadsheet_fn, 
                                                           sheet_name=sheet_name, 
                                                           check_sname=True)
    print("HPLC batch file has been created in %s: %s" % (winDataPath,batch_fn))
    input("please start batch data collection from the Shimadzu software, then hit enter:")
    for sn in samples:
        try:
            os.remove(default_hplc_export_file)
        except Exception as err:
            print(err)
        collect_hplc(sn, exp=exp)
        for i in range(save_retry):
            try: 
                uid=db[-1].start['uid']
                pack_h5(uid, attach_uv_file=True, delete_old_file=True)
            except Exception as err:
                print('h5 packing failed:', err)  
                print('retry # %d'%i, )
            else:
                break
        if i==save_retry:
            print('h5 packing is unsuccessful after %d retries for uid=%s.' % (i,uid))
    print('batch collection collected for %s from %s' % (sheet_name,spreadsheet_fn))
    